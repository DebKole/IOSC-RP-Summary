<table class="dataframe pdf-table">
  <thead>
    <tr style="text-align: right;">
      <th>GSM8K (Cobbe et al., 2021), MATH (Hendrycks et al., 2021), MGSM-zh (i et al., 2023), an</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Math (Wei et al., 2023). DeepSeek 67B exhibits exceptional performance on math-related task</td>
    </tr>
    <tr>
      <td>ross different languages, showcasing its superiority in this domain. In addition, DeepSee</td>
    </tr>
    <tr>
      <td>LM can utilize programs to solve math problems, which demonstrates better performance tha</td>
    </tr>
    <tr>
      <td>ain-of-thoughts. It is significantly better than the previous SOTA model, ToRA (Gou et al.</td>
    </tr>
    <tr>
      <td>23), on the benchmarks.</td>
    </tr>
    <tr>
      <td>Inference GSM8K MATH MGSM-zh CMath</td>
    </tr>
    <tr>
      <td>Chain-of-Thoughts</td>
    </tr>
    <tr>
      <td>MetaMath 70B (Yu et al., 2023) CoT 82.3% 26.6% 66.4% 70.9%</td>
    </tr>
    <tr>
      <td>WizardMath 70B (Luo et al., 2023) CoT 81.6% 22.7% 64.8% 65.4%</td>
    </tr>
    <tr>
      <td>DeepSeek LLM 67B Chat CoT 84.1% 32.6 % 74.0% 80.3%</td>
    </tr>
    <tr>
      <td>Tool-Integrated Reasoning</td>
    </tr>
    <tr>
      <td>ToRA-Code 34B (Gou et al., 2023) Tool-Integrated 80.7% 50.8% 41.2% 53.4%</td>
    </tr>
    <tr>
      <td>DeepSeek LLM 67B Chat Tool-Integrated 86.7% 51.1% 76.4% 85.4%</td>
    </tr>
  </tbody>
</table>